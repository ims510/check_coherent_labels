{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0 False False False False True False False False False False False\n",
      "  False False False True False False False False False False False False\n",
      "  True False False False False False False True False False False False\n",
      "  False False False False False True False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False False True False False True False True False True False False\n",
      "  True False True False True]\n",
      " [2.0 1 True False False False False False False False False False True\n",
      "  False False False False False False False False False False False False\n",
      "  False True False False False True False False False False False False\n",
      "  False False False False True False False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False False False True False True False True False True False False\n",
      "  True False True False True]\n",
      " [3.0 1 False False False False False False False True False False False\n",
      "  False False False False False True False False False False False False\n",
      "  True False False False False False False True False False False False\n",
      "  True False False False False False False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False False True False False True False True False True False False\n",
      "  True False True False True]\n",
      " [4.0 1 False False True False False False False False False False False\n",
      "  False True False False False False False False False False False False\n",
      "  False True False False True False False False False False False False\n",
      "  False False False False True False False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False False False True False True False True False True False False\n",
      "  True False True False True]\n",
      " [5.0 6 False False False False False True False False False False False\n",
      "  False False False False False False True False False False True False\n",
      "  False False False False False False True False False False False True\n",
      "  False False False False False False False True False True False True\n",
      "  False True False True False False True False True False False True\n",
      "  False False False True False True False True False True False False\n",
      "  True False True False True]\n",
      " [6.0 7 False False False False False False False False True False False\n",
      "  False False False False False False False True False False False True\n",
      "  False False False False False False False False True False False False\n",
      "  False True False False False False False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False True False False False True False True False True False False\n",
      "  True False True False True]\n",
      " [7.0 1 False False False False False False False False False True False\n",
      "  False False False False False False False False True False False False\n",
      "  False False True False False False False False False True False False\n",
      "  False False False True False False False True False True False True\n",
      "  False True False False True False True False True False True False\n",
      "  False False False True False True False True False True False True\n",
      "  False False True False True]\n",
      " [8.0 7 False False False False False False True False False False False\n",
      "  False False False False True False False False False False False False\n",
      "  True False False False False False False True False False False False\n",
      "  False False True False False False False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False False True False False True False True False True False False\n",
      "  True False True False True]\n",
      " [9.0 8 False False False True False False False False False False False\n",
      "  False False True False False False False False False False False False\n",
      "  True False False False False False False True False False False False\n",
      "  True False False False False False False True False True False True\n",
      "  False True False False True False True False True False False True\n",
      "  False False True False False True False True False True False False\n",
      "  True False True False True]\n",
      " [10.0 '...' False True False False False False False False False False\n",
      "  False True False False False False False False False False True False\n",
      "  False False False False True False False False False False False True\n",
      "  False False False False False False False True False True False True\n",
      "  False True False True False False True False True False True False\n",
      "  False True False False False True False True False True False True\n",
      "  False False True False True False]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'w': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n",
    "    'l': ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', '...'],\n",
    "    'x': ['Al', '-', 'Zaman', ':', 'american', 'force', 'kill', 'Shaikh', 'Abdullah', '...'],\n",
    "    'p': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', '...'],\n",
    "    'g': ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', '...'],\n",
    "    'f': [0, 1, 1, 1, 6, 7, 1, 7, 8, '...'],\n",
    "    'e': ['root', 'punct', 'flat', 'punct', 'amod', 'nsubj', 'parataxis', 'obj', 'flat', '...'],\n",
    "    'type': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'gender': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Case': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Definite': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Degree': ['_', '_', '_', '_', 'Pos', '_', '_', '_', '_', '...'],\n",
    "    'Foreign': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Gender': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Mood': ['_', '_', '_', '_', '_', '_', 'Ind', '_', '_', '...'],\n",
    "    'Number': ['Sing', '_', 'Sing', '_', '_', 'Plur', '_', 'Sing', 'Sing', '...'],\n",
    "    'Person': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Poss': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Reflex': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Tense': ['_', '_', '_', '_', '_', '_', 'Past', '_', '_', '...'],\n",
    "    'Voice': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...'],\n",
    "    'Type': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '...']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['l', 'x', 'p', 'g', 'e', 'type', 'gender', 'Case', 'Definite', 'Degree', 'Foreign', 'Gender', 'Mood', 'Number', 'Person', 'Poss', 'Reflex', 'Tense', 'Voice', 'Type']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Convert to vector\n",
    "vectors = df_encoded.values\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoded DataFrame:\n",
      "   color_blue  color_green  color_red\n",
      "0         0.0          0.0        1.0\n",
      "1         0.0          1.0        0.0\n",
      "2         1.0          0.0        0.0\n",
      "3         0.0          1.0        0.0\n",
      "4         0.0          0.0        1.0\n",
      "\n",
      "Label Encoded DataFrame:\n",
      "   color\n",
      "0      2\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "data = {'color': ['red', 'green', 'blue', 'green', 'red']}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(df[['color']])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded.toarray(), columns=one_hot_encoder.get_feature_names_out(['color']))\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoded = label_encoder.fit_transform(df['color'])\n",
    "label_df = pd.DataFrame(label_encoded, columns=['color'])\n",
    "\n",
    "print(\"One-Hot Encoded DataFrame:\")\n",
    "print(one_hot_df)\n",
    "print(\"\\nLabel Encoded DataFrame:\")\n",
    "print(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color\n",
      "0    red\n",
      "1  green\n",
      "2   blue\n",
      "3  green\n",
      "4    red\n",
      "   color\n",
      "0      2\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      2\n",
      "--------------------------------------------------\n",
      "{'blue': 0, 'green': 1, 'red': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "data = {'color': ['red', 'green', 'blue', 'green', 'red']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "label_encoder = LabelEncoder()\n",
    "df['color'] = label_encoder.fit_transform(df['color'])\n",
    "print(df)\n",
    "print(\"-\"*50)\n",
    "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_).tolist()))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/input/test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from conll_df import conll_df\n",
    "path = 'data/input/ro_rrt-ud-train.conllu'\n",
    "df = conll_df(path, file_index=True)\n",
    "df.head(40).to_csv('data/output/ro_rrt-ud-train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyconll\n",
    "\n",
    "data = pyconll.load_from_file(\"data/input/test.conllu\")\n",
    "tokens =[]\n",
    "for sentence in data:\n",
    "    for token in sentence:\n",
    "        token_info = {\n",
    "            'id': token.id,\n",
    "            'form': token.form,\n",
    "            'lemma': token.lemma,\n",
    "            'upos': token.upos,\n",
    "            'xpos': token.xpos,\n",
    "            'head': token.head,\n",
    "            'deprel': token.deprel,\n",
    "            'deps': token.deps,\n",
    "            'misc': token.misc\n",
    "        }\n",
    "        for key, value in token.feats.items():\n",
    "            token_info[key] = value\n",
    "        tokens.append(token_info)\n",
    "\n",
    "df = pd.DataFrame(tokens)\n",
    "df.to_csv('data/output/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def remove_value_from_column(df, column_name, value):\n",
    "    \"\"\"\n",
    "    Removes all occurrences of a value from a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    column_name (str): The name of the column from which to remove the value.\n",
    "    value: The value to be removed from the column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The resulting DataFrame with the value removed from the specified column.\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].replace(value, np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = remove_value_from_column(df, 'deprel', 'punct')\n",
    "new_df.to_csv('data/output/test_values_removed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This',\n",
    "    'This ',\n",
    "    'And',\n",
    "    'Is',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()\n",
    "print(X.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
